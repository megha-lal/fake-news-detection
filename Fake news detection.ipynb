{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0e1624f",
   "metadata": {},
   "source": [
    "# Fake News Detection "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8805709",
   "metadata": {},
   "source": [
    "**Problem statement**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3722c16",
   "metadata": {},
   "source": [
    "Develop an algorithm or model that can automatically identify and flag news articles, posts or videos as either authentic or fake. The objective is to create a reliable and efficient system that can help individuals and organizations to distinguish between real and fake news and promote the dissemination of accurate information.\n",
    "\n",
    "With the rise of social media and the increasing availability of online news sources, the spread of fake news has become a growing concern. The dissemination of false or misleading information can have serious consequences, such as influencing public opinion, damaging reputations, and even affecting election outcomes.\n",
    "\n",
    "The main challenges in building a fake news detection model include dealing with the large amount of unstructured data, addressing the issue of bias, and identifying the subtle differences between genuine and fake news."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295e4ecd",
   "metadata": {},
   "source": [
    "**Dateset**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead72aa2",
   "metadata": {},
   "source": [
    "The dataset contains a collection of articles from various news sources. The dataset consists of two main parts: a training set and a test set.\n",
    "\n",
    "The training set contains 20,800 articles, with each article being labeled as either \"Real\" or \"Fake\". The articles were collected from various sources, including news websites, blogs, and social media. Reliable news is labelled as 0 and unreliable is labelled as 1.\n",
    "\n",
    "The test set contains 5,200 articles, which are unlabelled and used for testing the models' performance.\n",
    "\n",
    "The dataset is collected from kaggale.\n",
    "\n",
    "Link to the dataset : https://www.kaggle.com/competitions/fake-news/data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5d60b2",
   "metadata": {},
   "source": [
    "**Model selection**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d7cc63",
   "metadata": {},
   "source": [
    "**Word2Vec**\n",
    "\n",
    "Word2vec is a neural network-based algorithm used to learn vector representations of words in a high-dimensional space. It captures semantic and syntactic similarities between words, so that similar words are mapped to nearby points in the vector space. The algorithm uses a skip-gram or CBOW model to learn word embeddings, which represent words as dense, low-dimensional vectors. Word2vec has various applications in natural language processing such as text classification, machine translation, and sentiment analysis. It is widely used to improve the accuracy of speech recognition systems and to train language models for generating text.\n",
    "\n",
    "Word2Vec is ideal for fake news detection because it can capture the semantic and syntactic similarities between words, and can represent words as dense, low-dimensional vectors. This makes it possible to identify patterns and relationships between words in text data. By training a Word2Vec model on a large corpus of both real and fake news articles, the model can learn to distinguish between the language used in authentic news articles and the language used in fake news articles.\n",
    "\n",
    "For example, a Word2Vec model may learn that certain words or phrases commonly appear together in fake news articles but not in real news articles, such as \"hoax\", \"conspiracy\", or \"unverified sources\". By analyzing the word embeddings learned by the model, it may be possible to identify the distinctive features of fake news articles and develop an algorithm or model that can detect them with a high degree of accuracy.\n",
    "\n",
    "**LSTM**\n",
    "\n",
    "LSTM (Long Short-Term Memory) is a type of recurrent neural network (RNN) that is commonly used in natural language processing and other sequential data applications. LSTM networks can learn long-term dependencies between input sequences, which is particularly useful for text data. LSTMs are designed to prevent the vanishing gradient problem that can occur in traditional RNNs by using memory cells and gates to control the flow of information through the network. The cells are used to store information for long periods of time, while the gates can selectively allow or block the flow of information based on the input data. This allows LSTMs to effectively model complex relationships and patterns in sequential data.\n",
    "\n",
    "LSTMs are ideal for fake news detection because they are particularly well-suited for analyzing sequential data such as text. Fake news detection often involves identifying patterns and relationships between words and phrases in news articles, which can be captured by LSTM models.\n",
    "\n",
    "By training an LSTM model on a large corpus of both real and fake news articles, the model can learn to identify the distinctive features of fake news articles, such as sensationalist language, unverified sources, or conspiracy theories. This can help to develop an algorithm or model that can detect fake news articles with a high degree of accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884665f4",
   "metadata": {},
   "source": [
    "**Implementation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a060bb",
   "metadata": {},
   "source": [
    "**Word2Vec**\n",
    "\n",
    "Word2Vec is implemented using the Gensim library.\n",
    "\n",
    "The 'sentences' parameter takes a list of sentences or a list of lists, where each sentence or list contains a sequence of words. This represents the training data for the model.\n",
    "\n",
    "The 'vector_size' parameter specifies the dimensionality of the word embeddings that the model will learn. In this case, it is set to 100.\n",
    "\n",
    "The 'window' parameter specifies the maximum distance between the target word and its surrounding context words in a sentence. The default value is 5, meaning that the model will consider the five words to the left and the five words to the right of the target word as context words.\n",
    "\n",
    "The 'min_count' parameter specifies the minimum frequency of a word in the training data for it to be included in the vocabulary. In this case, it is set to 1, meaning that all words will be included in the vocabulary.\n",
    "\n",
    "The Word2Vec function then trains the Word2Vec model on the training data, using the parameters specified. After training, the model can be used to generate word embeddings for any word in the vocabulary.\n",
    "\n",
    "**LSTM**\n",
    "\n",
    "Embedding Layer : The weights parameter sets the weights of the embedding layer to the pre-trained word embeddings that are passed in as embedding_vectors. The input_length parameter specifies the length of the input sequences, which is set to maxlen. The trainable parameter is set to False to keep the pre-trained weights fixed during training.\n",
    "\n",
    "LSTM Layers : Two LSTM layers with 128 memory units in each layer. The return_sequences parameter of the first LSTM layer is set to True to return the output sequences of each time step, which will be used as input to the second LSTM layer.\n",
    "\n",
    "Two LSTM layers are used instead of one to enable the model to learn more complex relationships between words in the text. The first LSTM layer is set to return sequences (return_sequences=True), which means that it will output the hidden state at each time step in the input sequence, rather than just the final hidden state. This output is then used as input to the second LSTM layer. By doing this, the second LSTM layer is able to build on the patterns learned by the first LSTM layer and capture more complex dependencies in the data. In effect, this creates a deeper network architecture, which has been shown to be effective in capturing complex patterns in sequential data. By adding more layers, the model can learn increasingly abstract and complex representations of the input data, which can improve its performance on the task of fake news detection.\n",
    "\n",
    "Dropout Layer : A Dropout layer is added to the model with a rate of 0.1 to prevent overfitting.\n",
    "\n",
    "Dense Layers : Two Dense layers with 32 and 1 units respectively. The relu activation function is used for the first Dense layer, and the sigmoid activation function is used for the output Dense layer.\n",
    "\n",
    "Two dense layers are used instead of one to add more non-linearity and complexity to the model. The first dense layer with 32 units and the relu activation function is used to introduce non-linearity to the model and create a more complex representation of the data. The relu activation function helps to address the vanishing gradient problem that can occur in deep neural networks, by allowing the model to maintain gradients throughout the network during backpropagation. The second dense layer with 1 unit and the sigmoid activation function is used as the output layer to produce a binary classification output, where a value closer to 0 represents a prediction of fake news and a value closer to 1 represents a prediction of real news. By using two dense layers, the model can learn more complex patterns in the data and increase its predictive accuracy. Adding more dense layers can lead to overfitting, so the number of layers should be chosen carefully based on the size of the dataset and the complexity of the task at hand. In this case, two dense layers seem to be sufficient to achieve good performance in fake news detection.\n",
    "\n",
    "Optimizer : The optimizer parameter is set to 'adam', which is a popular stochastic gradient descent algorithm that uses adaptive learning rates and momentum to update network weights during training. Adam is a good choice for this task because it has been shown to converge quickly and perform well on a wide range of problems.\n",
    "\n",
    "The loss parameter is set to 'binary_crossentropy', which is a loss function used for binary classification tasks. Binary cross-entropy measures the difference between the predicted probability distribution and the actual probability distribution. It is a popular choice for binary classification tasks and can penalize heavily for incorrect predictions.\n",
    "\n",
    "The metrics parameter is set to ['acc'], which specifies that the model should be evaluated based on its classification accuracy. The classification accuracy is the proportion of correct predictions made by the model over all predictions made. It is a common evaluation metric for classification tasks, but it can be misleading in cases where the classes are imbalanced.\n",
    "\n",
    "Finally, the embedding_vectors object is deleted to free up memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cb604f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary libraries\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Dropout, BatchNormalization\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bbbc0f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the train and test datasets\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "sample_subm = pd.read_csv('submit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0240e2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the 'id' and 'author' columns from the datasets\n",
    "train = train.drop(columns=['id', 'author']).fillna('')\n",
    "test = test.drop(columns=['id', 'author']).fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffad7c31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...   \n",
       "1  FLYNN: Hillary Clinton, Big Woman on Campus - ...   \n",
       "2                  Why the Truth Might Get You Fired   \n",
       "3  15 Civilians Killed In Single US Airstrike Hav...   \n",
       "4  Iranian woman jailed for fictional unpublished...   \n",
       "\n",
       "                                                text  label  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1  Ever get the feeling your life circles the rou...      0  \n",
       "2  Why the Truth Might Get You Fired October 29, ...      1  \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...      1  \n",
       "4  Print \\nAn Iranian woman has been sentenced to...      1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f826bdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why the Truth Might Get You FiredWhy the Truth...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1\n",
       "1  FLYNN: Hillary Clinton, Big Woman on Campus - ...      0\n",
       "2  Why the Truth Might Get You FiredWhy the Truth...      1\n",
       "3  15 Civilians Killed In Single US Airstrike Hav...      1\n",
       "4  Iranian woman jailed for fictional unpublished...      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Concatenating the title and text columns in the train and test datasets and dropping the title column\n",
    "try:\n",
    "    train.text = train.title + train.text\n",
    "    test.text = test.title + train.text\n",
    "    train.drop(columns=['title'], inplace=True)\n",
    "    test.drop(columns=['title'], inplace=True)\n",
    "except Exception as exc:\n",
    "    print(\"Columns are already dropped\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1126142",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\megha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hous dem aid we didn t even see comey s letter...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flynn hillari clinton big woman on campu breit...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>whi the truth might get you firedwhi the truth...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>civilian kill in singl us airstrik have been i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>iranian woman jail for fiction unpublish stori...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  hous dem aid we didn t even see comey s letter...      1\n",
       "1  flynn hillari clinton big woman on campu breit...      0\n",
       "2  whi the truth might get you firedwhi the truth...      1\n",
       "3  civilian kill in singl us airstrik have been i...      1\n",
       "4  iranian woman jail for fiction unpublish stori...      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Downloading the stopwords corpus from NLTK library.\n",
    "nltk.download('stopwords')\n",
    "port_stem = PorterStemmer()\n",
    "\n",
    "#Defining a function to take text column of train and test datasets and perform stemming on them\n",
    "def stemming(content):\n",
    "    review = re.sub('[^a-zA-Z]',' ',content) #Remove any character that is not a letter\n",
    "    review = review.lower() #Convert all letters to lower case\n",
    "    review = review.split() #Split the string into a list of words\n",
    "    review = list(map(port_stem.stem, review)) #Perform stemming on the list of words and replce them with the stemmed form\n",
    "    review = ' '.join(review) #Join the list of words to form a string with a space sepearating them \n",
    "    return review\n",
    "\n",
    "#Apply stemming on train and test datasets\n",
    "train.text = train.text.apply(stemming)\n",
    "test.text = test.text.apply(stemming)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32889257",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the text column into a list of list of words\n",
    "train_list = train.text.str.split().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe735827",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "\n",
    "#Word2Vec model\n",
    "w2v_model = Word2Vec(sentences=train_list, vector_size=EMBEDDING_DIM, window=5, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c41b94fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119419"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Retrieving the number of unique words in the vocabulary of the trained Word2Vec model\n",
    "len(w2v_model.wv.key_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fc91360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.623296  , -0.83466387, -0.12156601, -0.23185374, -0.42181826,\n",
       "        2.0699506 ,  0.89775187, -1.996735  , -0.8293047 ,  0.294101  ,\n",
       "       -1.3964146 ,  1.1978039 , -0.12341012,  0.05626316, -1.778223  ,\n",
       "        0.7359561 ,  2.7637327 ,  1.3669524 , -0.31847164, -0.55723983,\n",
       "       -1.101916  ,  2.1038804 , -1.1917374 , -0.81996614,  3.0275886 ,\n",
       "       -0.2655436 ,  0.7773566 ,  3.449984  , -1.8099395 ,  0.78424877,\n",
       "       -0.9013094 , -0.31634843, -1.5765237 ,  2.023271  ,  0.27161592,\n",
       "       -0.9198184 , -0.9164019 , -1.4209591 ,  0.12307112,  2.3140762 ,\n",
       "       -0.05010661,  1.959554  , -0.8199238 , -0.48460627,  0.3253545 ,\n",
       "        0.5535828 , -0.33303997,  0.2639708 ,  0.14924069, -2.496065  ,\n",
       "        1.1886649 ,  1.7281913 , -0.26699072,  2.0940893 ,  1.2678763 ,\n",
       "        1.5585569 , -0.82599396,  0.01609567,  1.3472779 , -1.0569754 ,\n",
       "       -0.577044  ,  0.36130297, -1.0441552 ,  1.0372669 ,  2.0561182 ,\n",
       "       -1.5964408 , -0.16226207, -2.6168416 ,  1.4923007 ,  1.8319584 ,\n",
       "        0.30852556, -0.9983582 , -1.8760638 ,  1.5991476 , -1.3239464 ,\n",
       "        0.75184155,  0.23462369,  0.6869493 ,  0.6164515 , -0.8616427 ,\n",
       "       -2.113034  , -1.6461387 ,  2.659459  , -0.06664529, -2.1403267 ,\n",
       "       -2.8666494 , -1.3419298 , -1.2896422 , -0.79258645,  0.41699612,\n",
       "        0.13159978, -0.56713104, -0.05207197,  0.13224651, -1.2927119 ,\n",
       "       -1.6093684 , -0.31794485, -0.6508411 ,  0.08617434,  0.8176449 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Word embedding for the word 'the' from the trained Word2Vec model\n",
    "w2v_model.wv['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9faa064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119419, 100)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Shape of the matrix containing the word embeddings in the Word2Vec model\n",
    "w2v_model.wv.vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b9f343",
   "metadata": {},
   "source": [
    "**Tokenizer**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ad9ed8",
   "metadata": {},
   "source": [
    "In natural language processing, tokenization is the process of breaking up a text into smaller units called tokens, which are typically words, phrases, or other meaningful units of text. Tokenization is an important preprocessing step in many NLP tasks, including language modeling, machine translation, and sentiment analysis.\n",
    "\n",
    "The Keras 'Tokenizer' class is a utility for tokenizing and encoding text data, which makes it easy to prepare text data for use in neural network models. The 'Tokenizer' class takes a text corpus as input and generates a dictionary that maps each unique word in the corpus to an integer index. This dictionary can then be used to convert the text data to sequences of integers, where each word is replaced with its corresponding integer index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71d662e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_list)\n",
    "\n",
    "X = tokenizer.texts_to_sequences(train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24727585",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 700 \n",
    "\n",
    "#Padding the sequences to a maximum length of 700\n",
    "X = pad_sequences(X, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "deef65d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119420"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f48aa3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a function that takes the Word2Vec model and vocabulary dictionary and returns a weight matrix that can be used for initializing the weights of an embedding layer in a neural network.\n",
    "def get_weight_matrix(model, vocab):\n",
    "    # total vocabulary size plus 1 for unknown words\n",
    "    vocab_size = len(vocab) + 1\n",
    "    # define weight matrix dimensions with all 0\n",
    "    weight_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\n",
    "    # for each word in vocabulary, corresponding word vector is retrieved from Word2Vec model\n",
    "    for word, i in vocab.items():\n",
    "        weight_matrix[i] = model.wv[word]\n",
    "    return weight_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c659e631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119420, 100)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "#Call the function to get weight matrix\n",
    "embedding_vectors = get_weight_matrix(w2v_model, word_index)\n",
    "embedding_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c237fd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# set embedding vectors as weights in Embedding layer \n",
    "model.add(Embedding(vocab_size, output_dim=EMBEDDING_DIM, weights=[embedding_vectors], input_length=maxlen, trainable=False))\n",
    "\n",
    "model.add(LSTM(units=128, return_sequences=True))\n",
    "model.add(LSTM(units=128))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "# delete embedding vectors object to free memory\n",
    "del embedding_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "01fd85e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_5 (Embedding)     (None, 700, 100)          11942000  \n",
      "                                                                 \n",
      " lstm_10 (LSTM)              (None, 700, 128)          117248    \n",
      "                                                                 \n",
      " lstm_11 (LSTM)              (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 32)                4128      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,194,993\n",
      "Trainable params: 252,993\n",
      "Non-trainable params: 11,942,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b2f1f75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, train.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c3d3e087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "488/488 [==============================] - 479s 982ms/step - loss: 0.2652 - acc: 0.8951 - val_loss: 0.2105 - val_acc: 0.9192\n",
      "Epoch 2/7\n",
      "488/488 [==============================] - 514s 1s/step - loss: 0.1819 - acc: 0.9294 - val_loss: 0.1635 - val_acc: 0.9340\n",
      "Epoch 3/7\n",
      "488/488 [==============================] - 1697s 3s/step - loss: 0.1497 - acc: 0.9419 - val_loss: 0.1520 - val_acc: 0.9413\n",
      "Epoch 4/7\n",
      " 60/488 [==>...........................] - ETA: 8:10 - loss: 0.0907 - acc: 0.9651"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [72]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1642\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1643\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1644\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1648\u001b[0m ):\n\u001b[0;32m   1649\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1650\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1651\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1652\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    877\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    879\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 880\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    882\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    883\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    909\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    910\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    911\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 912\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    914\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    915\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    916\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    132\u001b[0m   (concrete_function,\n\u001b[0;32m    133\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1741\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1744\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1745\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1746\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1747\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m     args,\n\u001b[0;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1750\u001b[0m     executing_eagerly)\n\u001b[0;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    377\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 378\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    384\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    386\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    387\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    390\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    391\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=7, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "054ecd75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "53be11a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 40s 242ms/step\n"
     ]
    }
   ],
   "source": [
    "test_seqs = tokenizer.texts_to_sequences(test.text.str.split().to_list())\n",
    "test_seqs = pad_sequences(test_seqs, maxlen=maxlen)\n",
    "preds = model.predict(test_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5da58948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       0\n",
       "2       1\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "5195    1\n",
       "5196    0\n",
       "5197    1\n",
       "5198    1\n",
       "5199    0\n",
       "Name: label, Length: 5200, dtype: int32"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_subm.label = (preds > 0.5).astype(int)\n",
    "sample_subm.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "67deed80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.4992720796024444\n",
      "Recall: 0.4994230769230769\n",
      "F1-Score: 0.4993223071220693\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f1_score, support = precision_recall_fscore_support(y_test, sample_subm.label, average='weighted')\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "39942ff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20801</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20802</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20803</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20804</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  label\n",
       "0  20800      1\n",
       "1  20801      0\n",
       "2  20802      1\n",
       "3  20803      1\n",
       "4  20804      1"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_subm.to_csv('subm.csv', index=False)\n",
    "sample_subm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64af9ea",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
